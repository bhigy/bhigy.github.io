---
title: Understanding visually grounded spoken language via multi-tasking
subtitle: An alternative approach for intelligent systems to understand human speech
layout: default
modal-id: 1
date: 2018-03-19
img: vgslu.jpg
thumbnail: vgslu-thumbnail.jpg
alt: A microphone
project-date: June 2019 - May 2021
client: Tilburg University
category: Spoken language understanding, Visual grounding, Multimodality, Multitask learning, Deep learning
description: Postdoctoral research position on a project titled <a href="https://www.esciencecenter.nl/projects/understanding-visually-grounded-spoken-language-via-multi-tasking/">Understanding visually grounded spoken language via multi-tasking</a>, under the supervision of <a href=http://grzegorz.chrupala.me/>Gregorz Chrupa≈Ça</a> and <a href=http://afra.alishahi.name/>Afra Alishahi</a>. This project explores how visually-grounded models of spoken language can benefit from other tasks such as transcribing speech, matching sentences in different languages or answering questions about images.

---
